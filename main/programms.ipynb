{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# measure weights for mulitple epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import train\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-s', '--seed',\n",
    "    type=float,\n",
    "    default=1,\n",
    "    help=\"Seed for randomness\",\n",
    "    dest=\"seed\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, give all for all layers\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "model_str = args.name\n",
    "layer_str = args.layer\n",
    "tf.random.set_seed(args.seed)\n",
    "\n",
    "exec(open(model_str+'/'+model_str+\".py\").read())\n",
    "model.load_weights(model_str+'/saved_model/'+model_str)\n",
    "# for 5000 epochs use \"measure_epochs_only=True\"\n",
    "model, weights = train.weight_measure(\n",
    "    model, layer_str, 10, final_learning_rate, x_train, y_train, batch_size)\n",
    "np.save(model_str+'/weights_'+layer_str, weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, give all for all layers\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "args = parser.parse_args()\n",
    "model_str = args.name\n",
    "layer_str = args.layer\n",
    "\n",
    "weights = np.load(model_str+'/weights_'+layer_str+'.npy')\n",
    "Cov = np.cov(weights.T)\n",
    "variance, pcomp_cov = np.linalg.eigh(Cov)\n",
    "pcomp = pcomp_cov.T[::-1]\n",
    "np.save(model_str+'/pc_'+layer_str, pcomp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, give all for all layers\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "args = parser.parse_args()\n",
    "model_str = args.name\n",
    "layer_str = args.layer\n",
    "\n",
    "weights = np.load(model_str+'/weights_'+layer_str+'.npy')\n",
    "pcomp = np.load(model_str+'/pc_'+layer_str+'.npy')\n",
    "theta = np.tensordot(weights, pcomp, axes=[1, 1])\n",
    "np.save(model_str+'/theta_'+layer_str, theta.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute singular value field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import analysis\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, all or layer of sv\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-m', '--mode',\n",
    "    type=str,\n",
    "    default=\"evh\",\n",
    "    help=\"type of input vectors, evh or pc\",\n",
    "    dest=\"mode\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '-lx', '--lyrdex',\n",
    "    type=int,\n",
    "    default=\"-1\",\n",
    "    help=\"layer index for singular values\",\n",
    "    dest=\"lx\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "model_str = args.name\n",
    "md_str = args.mode\n",
    "layer_index = args.lx\n",
    "layer_str = args.layer\n",
    "\n",
    "\n",
    "exec(open(model_str+'/'+model_str+\".py\").read())\n",
    "field = analysis.sv_field(model, model_str, layer_str, md_str,layer_index)\n",
    "if md_str == \"evh\":\n",
    "    if layer_str == \"all\":\n",
    "        np.save(model_str+'/field_'+str(layer_index), field)\n",
    "    else:\n",
    "        np.save(model_str+'/field_'+layer_str, field)\n",
    "else:\n",
    "    np.save(model_str+'/field_'+layer_str+'_'+md_str, field)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute accuracies and losses for different number of components added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import analysis\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, give all for all layers\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-m', '--mode',\n",
    "    type=str,\n",
    "    default=\"evh\",\n",
    "    help=\"type of input vectors, evh or pc\",\n",
    "    dest=\"mode\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-a', '--abs',\n",
    "    type=bool,\n",
    "    default=True,\n",
    "    help=\"whether eigenvalues should be added in order of magnitude or sign\",\n",
    "    dest=\"abs\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "model_str = args.name\n",
    "md_str = args.mode\n",
    "layer_str = args.layer\n",
    "\n",
    "\n",
    "exec(open(model_str+'/'+model_str+\".py\").read())\n",
    "model.load_weights(model_str+'/saved_model/'+model_str)\n",
    "if md_str == \"evh\":\n",
    "    if args.abs:\n",
    "        sort_list = np.argsort(\n",
    "            np.abs(np.load(model_str+'/ewh_'+layer_str+'.npy')))\n",
    "        vec = np.take(np.load(model_str+'/evh_'+layer_str+'.npy'),\n",
    "                      sort_list, axis=0)[::-1]\n",
    "    else:\n",
    "        vec = np.load(model_str+'/evh_'+layer_str+'.npy')\n",
    "else:\n",
    "    vec = np.load(model_str+'/'+md_str+'.npy')\n",
    "accs = analysis.acc_components(\n",
    "    model, layer_str, vec, x_train, y_train, x_test, y_test)\n",
    "if args.abs:\n",
    "    np.save(model_str+'/accabs_'+layer_str+md_str, accs)\n",
    "else:\n",
    "    np.save(model_str+'/acc_'+layer_str+md_str, accs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute loss landscape in directions of the weights and drift mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import analysis\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, give all for all layers\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "model_str = args.name\n",
    "layer_str = args.layer\n",
    "\n",
    "exec(open(model_str+'/'+model_str+\".py\").read())\n",
    "model.load_weights(model_str+'/saved_model/'+model_str)\n",
    "\n",
    "\n",
    "layer_pointer = analysis.get_layer_pointer(model, layer_str)\n",
    "weights = analysis.get_weights(layer_pointer)\n",
    "\n",
    "shift_step = 0.01\n",
    "epsilons = np.arange(-1, 3, shift_step)\n",
    "landscape_array = analysis.loss_landscape(\n",
    "    model, layer_str, weights, epsilons, x_train, y_train, x_test, y_test)\n",
    "np.save(model_str+'/loss_scaling_'+layer_str, landscape_array)\n",
    "\n",
    "pc = np.load(model_str+'/pc_'+layer_str+'.npy')\n",
    "shift_step = 0.001\n",
    "epsilons = np.arange(-0.05, 0.05, shift_step)\n",
    "landscape_array = analysis.loss_landscape(\n",
    "    model, layer_str, pc[0], epsilons, x_train, y_train, x_test, y_test)\n",
    "np.save(model_str+'/loss_pc_'+layer_str, landscape_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute loss landscape in direction of Hessian eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(\n",
    "    prog='train MLP256',\n",
    "    description='train MLP256',\n",
    "    epilog='Based on the rmt package.')\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, give all for all layers\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "model_str = args.name\n",
    "layer_str = args.layer\n",
    "\n",
    "exec(open(model_str+'/'+model_str+\".py\").read())\n",
    "model.load_weights(model_str+'/saved_model/'+model_str)\n",
    "\n",
    "\n",
    "evh = np.load(model_str+'/evh_'+layer_str+'.npy')\n",
    "\n",
    "\n",
    "layer_pointer = analysis.get_layer_pointer(model, layer_str)\n",
    "weights = analysis.get_weights(layer_pointer)\n",
    "\n",
    "weights_prod = np.tensordot(weights, evh, axes=(0, 1))\n",
    "max_entry = np.argmax(weights_prod)\n",
    "step_range = 0  # evh.shape[0]\n",
    "\n",
    "step_array = np.concatenate(([0], [max_entry]))\n",
    "shift_step = 0.01\n",
    "for i in step_array:\n",
    "    shift = weights_prod[i]\n",
    "    epsilons = np.arange(shift-weights_prod[max_entry]-shift_step,\n",
    "                         2*shift_step+shift+weights_prod[max_entry], shift_step)\n",
    "    landscape_array = analysis.loss_landscape(\n",
    "    model, layer_str, evh[i], epsilons-shift, x_train, y_train, x_test, y_test)\n",
    "    np.save(model_str+'/evh_eps_'+layer_str+'_'+str(i),\n",
    "            [epsilons,landscape_array[1:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute component comparison between 2 bases\n",
    "import numpy as np\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, all or layer of sv\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-m1', '--mode1',\n",
    "    type=str,\n",
    "    default=\"evh\",\n",
    "    help=\"component mode 1\",\n",
    "    dest=\"mode1\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-m2', '--mode2',\n",
    "    type=str,\n",
    "    default=\"vc\",\n",
    "    help=\"component mode 2\",\n",
    "    dest=\"mode2\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "args=parser.parse_args()\n",
    "model_str=args.name\n",
    "md_1_str=args.mode1\n",
    "md_2_str=args.mode2\n",
    "layer_str=args.layer\n",
    "\n",
    "comp_1=np.load(model_str+'/'+md_1_str+'_'+layer_str+'.npy')\n",
    "comp_2=np.load(model_str+'/'+md_2_str+'_'+layer_str+'.npy')\n",
    "field=np.tensordot(comp_1,comp_2,axes=(1,1))\n",
    "np.save(model_str+'/comp_'+md_1_str+'_'+md_2_str+'_'+str(layer_index),field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute component comparison layer and full network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, all or layer of sv\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-m', '--mode',\n",
    "    type=str,\n",
    "    default=\"evh\",\n",
    "    help=\"type of input vectors, evh or pc\",\n",
    "    dest=\"mode\"\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    '-lx', '--lyrdex',\n",
    "    type=int,\n",
    "    default=\"-1\",\n",
    "    help=\"layer index for singular values\",\n",
    "    dest=\"lx\"\n",
    ")\n",
    "\n",
    "args=parser.parse_args()\n",
    "model_str=args.name\n",
    "md_str=args.mode\n",
    "layer_index=args.lx\n",
    "layer_str=args.layer\n",
    "\n",
    "exec(open(model_str+'/'+model_str+\".py\").read())\n",
    "model.load_weights(model_str+'/saved_model/'+model_str)\n",
    "\n",
    "if layer_str[:6] == \"layers\":\n",
    "        layer_name = [getattr(model, \"layers\")[int(\n",
    "            layer_str[7:(len(layer_str)-1)])]]\n",
    "        layer_index= layer_str[7:(len(layer_str)-1)]\n",
    "else:\n",
    "    layer_name = [getattr(model, layer_str)]\n",
    "layer_shape=layer_name.get_weights()[0].shape\n",
    "layer_size=1\n",
    "for i in layer_name.get_weights()[0].shape:\n",
    "    layer_size*=i\n",
    "weight_list=model.trainable_weights\n",
    "i_start=0\n",
    "for layer in weight_list[:layer_index]:\n",
    "    i_start+=np.prod(layer.shape)\n",
    "evh=np.load(model_str+'/'+md_str+'_all'+'.npy')[:,i_start:i_start+layer_size]\n",
    "evh_layer=np.load(model_str+'/'+md_str+'_'+layer_str+'.npy')\n",
    "field=np.tensordot(evh_layer,evh,axes=(1,1))\n",
    "np.save(model_str+'/comp_'+md_str+'_'+str(layer_index),field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute Hessian eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import hess\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, all or layer of sv\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "\n",
    "args=parser.parse_args()\n",
    "model_str=args.name\n",
    "layer_str=args.layer\n",
    "\n",
    "exec(open(model_str+'/'+model_str+\".py\").read())\n",
    "model.load_weights(model_str+'/saved_model/'+model_str)\n",
    "ewh,evh=hess.comp_eig(model,layer_str,x_train,y_train)\n",
    "np.save(model_str+'/ewh_'+layer_str,ewh)\n",
    "np.save(model_str+'/evh_'+layer_str,evh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute weights product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import analysis\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-l', '--layer',\n",
    "    type=str,\n",
    "    default=\"all\",\n",
    "    help=\"layer_name, all or layer of sv\",\n",
    "    dest=\"layer\"\n",
    ")\n",
    "\n",
    "args=parser.parse_args()\n",
    "model_str=args.name\n",
    "layer_str=args.layer\n",
    "\n",
    "exec(open(model_str+'/'+model_str+\".py\").read())\n",
    "model.load_weights(model_str+'/saved_model/'+model_str)\n",
    "weights_prod=analysis.evh_weights_prod(model,model_str,layer_str)\n",
    "np.save(model_str+'/weights_prod_'+layer_str,weights_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wigner surmise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import analysis\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '-n', '--name',\n",
    "    type=str,\n",
    "    default=\"missing name\",\n",
    "    help=\"Name of network\",\n",
    "    dest=\"name\"\n",
    ")\n",
    "args=parser.parse_args()\n",
    "model_str=args.name\n",
    "layer_str=args.layer\n",
    "ewh=np.load(model_str+'/ewh_'+layer_str+'.npy')\n",
    "# width of the gaussian in the unfolding process\n",
    "average = 10\n",
    "spacings = analysis.wigner(ewh, average) \n",
    "np.save(model_str+'/spacings',spacings)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
