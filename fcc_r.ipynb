{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGFvpVclO7ob"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import time\n",
        "dense_size=64\n",
        "\n",
        "# load the data set\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train,x_test=x_train/255,x_test/255\n",
        "\n",
        "# normalise the data\n",
        "for i in range(x_train.shape[0]):\n",
        "    x_train[i]-=np.mean(x_train[i],axis=(0,1))\n",
        "    x_train[i]/=np.std(x_train[i],axis=(0,1))\n",
        "for i in range(x_test.shape[0]):\n",
        "    x_test[i]-=np.mean(x_test[i],axis=(0,1))\n",
        "    x_test[i]/=np.std(x_test[i],axis=(0,1))\n",
        "# set the seed\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "\n",
        "# choose Parameter\n",
        "learning_rate = 1e-2\n",
        "batch_size = 64\n",
        "epochs = 800\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(batch_size)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hekkUd0XSWtn"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.flatten = layers.Flatten()\n",
        "    self.d1 = layers.Dense(dense_size, activation='relu',kernel_regularizer=tf.keras.regularizers.L2(5e-5))\n",
        "    self.d2 = layers.Dense(dense_size, activation='relu',kernel_regularizer=tf.keras.regularizers.L2(5e-5))\n",
        "    self.d3 = layers.Dense(dense_size, activation='relu',kernel_regularizer=tf.keras.regularizers.L2(5e-5))\n",
        "    self.d4 = layers.Dense(10, activation='softmax',kernel_regularizer=tf.keras.regularizers.L2(5e-5))\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    x = self.d2(x)\n",
        "    x = self.d3(x)\n",
        "    return self.d4(x)\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTd3wh2xSUkW"
      },
      "outputs": [],
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "#train function\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # training=True is only needed if there are layers with different\n",
        "    # behavior during training versus inference (e.g. Dropout).\n",
        "    predictions = model(images, training=True)\n",
        "    loss=loss_fn(labels, predictions)\n",
        "    loss+=sum(model.losses)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)\n",
        "#test function\n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  # training=False is only needed if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_fn(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM7tHwNeO4N8"
      },
      "outputs": [],
      "source": [
        "history = np.zeros((epochs, 4))\n",
        "time_stemp = time.monotonic()\n",
        "time_stemp_0 = time_stemp\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # Reset the metrics at the start of the next epoch\n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_accuracy.reset_states()\n",
        "\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  history[epoch] = np.array([train_loss.result(), train_accuracy.result(), test_loss.result(), test_accuracy.result()])\n",
        "  time_temp = time.monotonic()\n",
        "  time_diff = time_temp - time_stemp\n",
        "  time_stemp = time_temp\n",
        "  time_total = time_temp - time_stemp_0\n",
        "  TREM = (epochs - epoch+1)*time_total/(epoch+1)\n",
        "  print(\n",
        "    f'Epoch {epoch + 1}, '\n",
        "    f'{time_diff:.0f}s, '\n",
        "    f'Loss: {train_loss.result():.2e}, '\n",
        "    f'Accuracy: {train_accuracy.result():.2e}, '\n",
        "    f'Test Loss: {test_loss.result():.2e}, '\n",
        "    f'Test Accuracy: {test_accuracy.result():.2e}, '\n",
        "    f'TREM: {TREM:.0f}s'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM4JNkkNr4u4"
      },
      "outputs": [],
      "source": [
        "model_str='fcc_model_64r'\n",
        "\n",
        "# saves the model for later use\n",
        "model.save('saved_model/'+model_str)\n",
        "np.save('history/history_'+model_str,history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['text.usetex'] = False\n",
        "plt.rc('font', size=18)\n",
        "plt.rcParams['figure.figsize'] = [10, 7]"
      ],
      "metadata": {
        "id": "dwTmbjROp1dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(1 - history[:,1], label = \"training error\")\n",
        "plt.plot(history[:,0], label = \"training loss\")\n",
        "\n",
        "\n",
        "plt.title(\"Entering the Exploration Phase with reg\")\n",
        "#plt.ylabel(r\"$S_{v,i}(t)$\")\n",
        "plt.xlabel(r\"$t$\")\n",
        "plt.legend()\n",
        "plt.yscale(\"log\")"
      ],
      "metadata": {
        "id": "BXJL-4foptXr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}